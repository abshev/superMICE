% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/mice_impute_SuperLearner.R
\name{mice.impute.SuperLearner}
\alias{mice.impute.SuperLearner}
\title{SuperLearner method for \code{mice} package.}
\usage{
mice.impute.SuperLearner(
  y,
  ry,
  x,
  wy = NULL,
  SL.library,
  kernel = "gaussian",
  bw = 0.1,
  imputation = "semiparametric",
  weights = "nadaraya-watson",
  ...
)
}
\arguments{
\item{y}{Vector to be imputed}

\item{ry}{Logical vector of length length(y) indicating the the subset y[ry]
of elements in y to which the imputation model is fitted. The ry generally
distinguishes the observed (TRUE) and missing values (FALSE) in y.}

\item{x}{Numeric design matrix with length(y) rows with predictors for y.
Matrix x may have no missing values.}

\item{wy}{Logical vector of length length(y). A TRUE value indicates
locations in y for which imputations are created.}

\item{SL.library}{For SuperLearner: Either a character vector of prediction
algorithms or list containing character vectors as specified by the
SuperLearner package.  For h2o, a named list of character vectors specifying
prediction algorithms and arguments to be passed to h2o.  See details below
for examples on the structure.}

\item{kernel}{One of "gaussian",...  Kernel function used to compute weights.}

\item{bw}{Numeric value for bandwidth to be used in the kernel function}

\item{imputation}{One of "semiparametric" or "nonparametric". Determines
distribution from which imputed values are drawn. See
mice.impute.SuperLearner() documentation for more details.}

\item{weights}{One of "nadaraya-watson", ...}

\item{...}{Further arguments passed to \code{SuperLearner} or \code{h2o}.}
}
\value{
Vector with imputed data, same type as y, and of length sum(wy)
}
\description{
Method for the \code{mice} package that uses SuperLearner as the predctive
algorithm.  This is done through a backend powered by either the
\code{SuperLearner} package or H2O.
}
\examples{
  n <- 1000
  pmissing <- 0.10
  x1 = runif(n, min = -3, max = 3)
  x2 = x1^2 + rnorm(n, mean = 0, sd = 1)
  error <- rnorm(n, mean = 0, sd = 1)
  y <- x1 + x2 + error
  f <- ecdf(x1)
  x2 <- ifelse(runif(x2) < (f(x1) * 2 * pmissing), NA, x2)
  dat <- data.frame(y, x1, x2)
  SL.lib <- c("SL.glm", "SL.glm.interaction", "SL.glmnet", "SL.loess")
  imp.SL <- mice::mice(dat, m = 5, method = "SuperLearner",
                         print = TRUE, SL.library = SL.lib,
                         kernel = "gaussian", bw = 0.1,
                         imputation = "semiparametric",
                         weights = "nadaraya-watson")

}
